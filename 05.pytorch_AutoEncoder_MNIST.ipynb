{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from torchvision import datasets\n",
    "from torch.utils.data import DataLoader\n",
    "from torch import optim\n",
    "from early_stopping import EarlyStopping\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "## load training and test data\n",
    "train_data = datasets.MNIST(root='./mnist',\n",
    "                            train = True,\n",
    "                            transform=torchvision.transforms.ToTensor(),\n",
    "                            download=True)\n",
    "\n",
    "test_data = datasets.MNIST(root='./mnist',\n",
    "                           train = False,\n",
    "                           transform=torchvision.transforms.ToTensor(),\n",
    "                           download=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "## split training data into training and validation\\\n",
    "num_train = len(train_data)\n",
    "indices = list(range(num_train))\n",
    "np.random.shuffle(indices)\n",
    "split = int(np.floor(num_train * 0.25))\n",
    "train_idx, valid_idx = indices[split:], indices[:split]\n",
    "    \n",
    "\n",
    "# define samplers for obtaining training and validation batches\n",
    "from torch.utils.data.sampler import SubsetRandomSampler\n",
    "\n",
    "train_sampler = SubsetRandomSampler(train_idx)\n",
    "valid_sampler = SubsetRandomSampler(valid_idx) \n",
    "\n",
    "## load data into batches\n",
    "BATCH_SIZE = 100\n",
    "\n",
    "train_loader = DataLoader(dataset=train_data, \n",
    "                          batch_size=BATCH_SIZE, \n",
    "                          sampler=train_sampler,\n",
    "                          num_workers=0)\n",
    "\n",
    "validation_loader = DataLoader(dataset=train_data, \n",
    "                               batch_size=BATCH_SIZE, \n",
    "                               sampler=valid_sampler,\n",
    "                               num_workers=0)\n",
    "\n",
    "test_loader = DataLoader(dataset=test_data, \n",
    "                         batch_size=BATCH_SIZE, \n",
    "                         num_workers=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Autoencoder Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Autoencoder(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Autoencoder,self).__init__()\n",
    "        self.fc1 = nn.Linear(28*28, 218)\n",
    "        self.fc2 = nn.Linear(218,64)\n",
    "        self.fc3 = nn.Linear(64,16)\n",
    "        self.fc4 = nn.Linear(16,2)\n",
    "        \n",
    "        self.fc5 = nn.Linear(2,16)\n",
    "        self.fc6 = nn.Linear(16, 64)\n",
    "        self.fc7 = nn.Linear(64, 218)\n",
    "        self.fc8 = nn.Linear(218, 28*28)\n",
    "\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = x.view(-1, 28*28)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = F.relu(self.fc3(x))\n",
    "        x = F.relu(self.fc4(x))\n",
    "        x = F.relu(self.fc5(x))\n",
    "        x = F.relu(self.fc6(x))\n",
    "        x = F.relu(self.fc7(x))\n",
    "        x = F.relu(self.fc8(x))\n",
    "        return x\n",
    "\n",
    "\n",
    "model = Autoencoder()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loss function\n",
    "criterion = nn.MSELoss()  \n",
    "\n",
    "# optimizer\n",
    "optimizer = optim.Adam(model.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_train(model, patience, max_epochs):\n",
    "    \n",
    "    train_losses = []\n",
    "    valid_losses = []\n",
    "    avg_train_losses = []  # average loss in epoch\n",
    "    avg_valid_losses = [] \n",
    "    \n",
    "    # early stopping\n",
    "    early_stopping = EarlyStopping(patience=patience, verbose=True)\n",
    "    \n",
    "    for epoch in range(1, max_epochs + 1):\n",
    "        ##X_train, y_train = shuffle(X_train, y_train)\n",
    "\n",
    "        #### 1.TRAINING PROCESS\n",
    "        model.train()\n",
    "        for batch in train_loader:\n",
    "            x, y = batch\n",
    "            #x = x.view(x.size(0), -1)\n",
    "            #y = y.to(torch.float32)\n",
    "            optimizer.zero_grad()\n",
    "            output = model(x)\n",
    "            #print('x: ', x.shape)\n",
    "            #print('output:', output.shape)\n",
    "\n",
    "            loss = criterion(output, x.view(-1, 28*28))\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            train_losses.append(loss.item())\n",
    "\n",
    "   \n",
    "        #### 2.VALIDATION PROCESS\n",
    "        model.eval() # prep model for evaluation\n",
    "        for batch in validation_loader:\n",
    "            x, y = batch\n",
    "            #x = x.view(x.size(0), -1)\n",
    "        \n",
    "            #y = y.to(torch.float32)\n",
    "            output = model(x)\n",
    "            loss = criterion(output, x.view(-1, 28*28))\n",
    "\n",
    "            valid_losses.append(loss.item())\n",
    "\n",
    "        #### 3.training/validation statistics \n",
    "        # average loss over an epoch\n",
    "        train_loss = np.average(train_losses)\n",
    "        valid_loss = np.average(valid_losses)\n",
    "        avg_train_losses.append(train_loss)\n",
    "        avg_valid_losses.append(valid_loss)\n",
    "        \n",
    "        epoch_len = len(str(max_epochs))\n",
    "        \n",
    "        print_msg = (f'[{epoch:>{epoch_len}}/{max_epochs:>{epoch_len}}] ' +\n",
    "                     f'train_loss: {train_loss:.5f} ' +\n",
    "                     f'valid_loss: {valid_loss:.5f}')\n",
    "        \n",
    "        print(print_msg)\n",
    "        \n",
    "        # clear lists to track next epoch\n",
    "        train_losses = []\n",
    "        valid_losses = []\n",
    "        \n",
    "        # early_stopping needs the validation loss to check if it has decresed, \n",
    "        # and if it has, it will make a checkpoint of the current model\n",
    "        early_stopping(valid_loss, model)\n",
    "        \n",
    "        if early_stopping.early_stop:\n",
    "            print(\"Early stopping\")\n",
    "            break\n",
    "        \n",
    "    # load the last checkpoint with the best model\n",
    "    model.load_state_dict(torch.load('checkpoint.pt'))\n",
    "\n",
    "    return  model, avg_train_losses, avg_valid_losses\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[  1/500] train_loss: 0.07025 valid_loss: 0.06075\n",
      "Validation loss decreased (inf --> 0.060749).  Saving model ...\n",
      "[  2/500] train_loss: 0.05627 valid_loss: 0.05388\n",
      "Validation loss decreased (0.060749 --> 0.053884).  Saving model ...\n",
      "[  3/500] train_loss: 0.05261 valid_loss: 0.05131\n",
      "Validation loss decreased (0.053884 --> 0.051307).  Saving model ...\n",
      "[  4/500] train_loss: 0.04964 valid_loss: 0.04882\n",
      "Validation loss decreased (0.051307 --> 0.048817).  Saving model ...\n",
      "[  5/500] train_loss: 0.04812 valid_loss: 0.04797\n",
      "Validation loss decreased (0.048817 --> 0.047973).  Saving model ...\n",
      "[  6/500] train_loss: 0.04705 valid_loss: 0.04716\n",
      "Validation loss decreased (0.047973 --> 0.047161).  Saving model ...\n",
      "[  7/500] train_loss: 0.04636 valid_loss: 0.04652\n",
      "Validation loss decreased (0.047161 --> 0.046524).  Saving model ...\n",
      "[  8/500] train_loss: 0.04576 valid_loss: 0.04565\n",
      "Validation loss decreased (0.046524 --> 0.045650).  Saving model ...\n",
      "[  9/500] train_loss: 0.04513 valid_loss: 0.04559\n",
      "Validation loss decreased (0.045650 --> 0.045595).  Saving model ...\n",
      "[ 10/500] train_loss: 0.04467 valid_loss: 0.04470\n",
      "Validation loss decreased (0.045595 --> 0.044701).  Saving model ...\n",
      "[ 11/500] train_loss: 0.04417 valid_loss: 0.04432\n",
      "Validation loss decreased (0.044701 --> 0.044316).  Saving model ...\n",
      "[ 12/500] train_loss: 0.04358 valid_loss: 0.04376\n",
      "Validation loss decreased (0.044316 --> 0.043761).  Saving model ...\n",
      "[ 13/500] train_loss: 0.04301 valid_loss: 0.04322\n",
      "Validation loss decreased (0.043761 --> 0.043225).  Saving model ...\n",
      "[ 14/500] train_loss: 0.04270 valid_loss: 0.04298\n",
      "Validation loss decreased (0.043225 --> 0.042976).  Saving model ...\n",
      "[ 15/500] train_loss: 0.04240 valid_loss: 0.04282\n",
      "Validation loss decreased (0.042976 --> 0.042816).  Saving model ...\n",
      "[ 16/500] train_loss: 0.04218 valid_loss: 0.04263\n",
      "Validation loss decreased (0.042816 --> 0.042631).  Saving model ...\n",
      "[ 17/500] train_loss: 0.04188 valid_loss: 0.04230\n",
      "Validation loss decreased (0.042631 --> 0.042304).  Saving model ...\n",
      "[ 18/500] train_loss: 0.04155 valid_loss: 0.04205\n",
      "Validation loss decreased (0.042304 --> 0.042047).  Saving model ...\n",
      "[ 19/500] train_loss: 0.04131 valid_loss: 0.04184\n",
      "Validation loss decreased (0.042047 --> 0.041836).  Saving model ...\n",
      "[ 20/500] train_loss: 0.04089 valid_loss: 0.04115\n",
      "Validation loss decreased (0.041836 --> 0.041155).  Saving model ...\n",
      "[ 21/500] train_loss: 0.04041 valid_loss: 0.04099\n",
      "Validation loss decreased (0.041155 --> 0.040988).  Saving model ...\n",
      "[ 22/500] train_loss: 0.04032 valid_loss: 0.04102\n",
      "EarlyStopping counter: 1 out of 35\n",
      "[ 23/500] train_loss: 0.04026 valid_loss: 0.04075\n",
      "Validation loss decreased (0.040988 --> 0.040755).  Saving model ...\n",
      "[ 24/500] train_loss: 0.04013 valid_loss: 0.04077\n",
      "EarlyStopping counter: 1 out of 35\n",
      "[ 25/500] train_loss: 0.04013 valid_loss: 0.04075\n",
      "Validation loss decreased (0.040755 --> 0.040749).  Saving model ...\n",
      "[ 26/500] train_loss: 0.03989 valid_loss: 0.04091\n",
      "EarlyStopping counter: 1 out of 35\n",
      "[ 27/500] train_loss: 0.03993 valid_loss: 0.04054\n",
      "Validation loss decreased (0.040749 --> 0.040543).  Saving model ...\n",
      "[ 28/500] train_loss: 0.03972 valid_loss: 0.04058\n",
      "EarlyStopping counter: 1 out of 35\n",
      "[ 29/500] train_loss: 0.03953 valid_loss: 0.04023\n",
      "Validation loss decreased (0.040543 --> 0.040228).  Saving model ...\n",
      "[ 30/500] train_loss: 0.03941 valid_loss: 0.04022\n",
      "Validation loss decreased (0.040228 --> 0.040220).  Saving model ...\n",
      "[ 31/500] train_loss: 0.03962 valid_loss: 0.04031\n",
      "EarlyStopping counter: 1 out of 35\n",
      "[ 32/500] train_loss: 0.03930 valid_loss: 0.04003\n",
      "Validation loss decreased (0.040220 --> 0.040031).  Saving model ...\n",
      "[ 33/500] train_loss: 0.03920 valid_loss: 0.03983\n",
      "Validation loss decreased (0.040031 --> 0.039831).  Saving model ...\n",
      "[ 34/500] train_loss: 0.03909 valid_loss: 0.03991\n",
      "EarlyStopping counter: 1 out of 35\n",
      "[ 35/500] train_loss: 0.03901 valid_loss: 0.03987\n",
      "EarlyStopping counter: 2 out of 35\n",
      "[ 36/500] train_loss: 0.03929 valid_loss: 0.04004\n",
      "EarlyStopping counter: 3 out of 35\n",
      "[ 37/500] train_loss: 0.03943 valid_loss: 0.03997\n",
      "EarlyStopping counter: 4 out of 35\n",
      "[ 38/500] train_loss: 0.03907 valid_loss: 0.03970\n",
      "Validation loss decreased (0.039831 --> 0.039703).  Saving model ...\n",
      "[ 39/500] train_loss: 0.03892 valid_loss: 0.03964\n",
      "Validation loss decreased (0.039703 --> 0.039642).  Saving model ...\n",
      "[ 40/500] train_loss: 0.03875 valid_loss: 0.03983\n",
      "EarlyStopping counter: 1 out of 35\n",
      "[ 41/500] train_loss: 0.03878 valid_loss: 0.03965\n",
      "EarlyStopping counter: 2 out of 35\n",
      "[ 42/500] train_loss: 0.03867 valid_loss: 0.03964\n",
      "Validation loss decreased (0.039642 --> 0.039642).  Saving model ...\n",
      "[ 43/500] train_loss: 0.03864 valid_loss: 0.03939\n",
      "Validation loss decreased (0.039642 --> 0.039387).  Saving model ...\n",
      "[ 44/500] train_loss: 0.03847 valid_loss: 0.03947\n",
      "EarlyStopping counter: 1 out of 35\n",
      "[ 45/500] train_loss: 0.03845 valid_loss: 0.03933\n",
      "Validation loss decreased (0.039387 --> 0.039326).  Saving model ...\n",
      "[ 46/500] train_loss: 0.03848 valid_loss: 0.03920\n",
      "Validation loss decreased (0.039326 --> 0.039204).  Saving model ...\n",
      "[ 47/500] train_loss: 0.03841 valid_loss: 0.03956\n",
      "EarlyStopping counter: 1 out of 35\n",
      "[ 48/500] train_loss: 0.03834 valid_loss: 0.03931\n",
      "EarlyStopping counter: 2 out of 35\n",
      "[ 49/500] train_loss: 0.03825 valid_loss: 0.03932\n",
      "EarlyStopping counter: 3 out of 35\n",
      "[ 50/500] train_loss: 0.03818 valid_loss: 0.03921\n",
      "EarlyStopping counter: 4 out of 35\n",
      "[ 51/500] train_loss: 0.03824 valid_loss: 0.03921\n",
      "EarlyStopping counter: 5 out of 35\n",
      "[ 52/500] train_loss: 0.03824 valid_loss: 0.03901\n",
      "Validation loss decreased (0.039204 --> 0.039008).  Saving model ...\n",
      "[ 53/500] train_loss: 0.03834 valid_loss: 0.03913\n",
      "EarlyStopping counter: 1 out of 35\n",
      "[ 54/500] train_loss: 0.03812 valid_loss: 0.03966\n",
      "EarlyStopping counter: 2 out of 35\n",
      "[ 55/500] train_loss: 0.03867 valid_loss: 0.03914\n",
      "EarlyStopping counter: 3 out of 35\n",
      "[ 56/500] train_loss: 0.03801 valid_loss: 0.03901\n",
      "EarlyStopping counter: 4 out of 35\n",
      "[ 57/500] train_loss: 0.03784 valid_loss: 0.03860\n",
      "Validation loss decreased (0.039008 --> 0.038601).  Saving model ...\n",
      "[ 58/500] train_loss: 0.03774 valid_loss: 0.03878\n",
      "EarlyStopping counter: 1 out of 35\n",
      "[ 59/500] train_loss: 0.03769 valid_loss: 0.03869\n",
      "EarlyStopping counter: 2 out of 35\n",
      "[ 60/500] train_loss: 0.03764 valid_loss: 0.03855\n",
      "Validation loss decreased (0.038601 --> 0.038552).  Saving model ...\n",
      "[ 61/500] train_loss: 0.03752 valid_loss: 0.03858\n",
      "EarlyStopping counter: 1 out of 35\n",
      "[ 62/500] train_loss: 0.03762 valid_loss: 0.03863\n",
      "EarlyStopping counter: 2 out of 35\n",
      "[ 63/500] train_loss: 0.03764 valid_loss: 0.03856\n",
      "EarlyStopping counter: 3 out of 35\n",
      "[ 64/500] train_loss: 0.03761 valid_loss: 0.03846\n",
      "Validation loss decreased (0.038552 --> 0.038465).  Saving model ...\n",
      "[ 65/500] train_loss: 0.03737 valid_loss: 0.03832\n",
      "Validation loss decreased (0.038465 --> 0.038324).  Saving model ...\n",
      "[ 66/500] train_loss: 0.03746 valid_loss: 0.03844\n",
      "EarlyStopping counter: 1 out of 35\n",
      "[ 67/500] train_loss: 0.03751 valid_loss: 0.03850\n",
      "EarlyStopping counter: 2 out of 35\n",
      "[ 68/500] train_loss: 0.03798 valid_loss: 0.03872\n",
      "EarlyStopping counter: 3 out of 35\n",
      "[ 69/500] train_loss: 0.03807 valid_loss: 0.03852\n",
      "EarlyStopping counter: 4 out of 35\n",
      "[ 70/500] train_loss: 0.03777 valid_loss: 0.03885\n",
      "EarlyStopping counter: 5 out of 35\n",
      "[ 71/500] train_loss: 0.03763 valid_loss: 0.03889\n",
      "EarlyStopping counter: 6 out of 35\n",
      "[ 72/500] train_loss: 0.03779 valid_loss: 0.03837\n",
      "EarlyStopping counter: 7 out of 35\n",
      "[ 73/500] train_loss: 0.03748 valid_loss: 0.03840\n",
      "EarlyStopping counter: 8 out of 35\n",
      "[ 74/500] train_loss: 0.03724 valid_loss: 0.03821\n",
      "Validation loss decreased (0.038324 --> 0.038213).  Saving model ...\n",
      "[ 75/500] train_loss: 0.03711 valid_loss: 0.03820\n",
      "Validation loss decreased (0.038213 --> 0.038201).  Saving model ...\n",
      "[ 76/500] train_loss: 0.03704 valid_loss: 0.03805\n",
      "Validation loss decreased (0.038201 --> 0.038054).  Saving model ...\n",
      "[ 77/500] train_loss: 0.03699 valid_loss: 0.03803\n",
      "Validation loss decreased (0.038054 --> 0.038032).  Saving model ...\n",
      "[ 78/500] train_loss: 0.03699 valid_loss: 0.03798\n",
      "Validation loss decreased (0.038032 --> 0.037982).  Saving model ...\n",
      "[ 79/500] train_loss: 0.03694 valid_loss: 0.03798\n",
      "Validation loss decreased (0.037982 --> 0.037977).  Saving model ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 80/500] train_loss: 0.03706 valid_loss: 0.03809\n",
      "EarlyStopping counter: 1 out of 35\n",
      "[ 81/500] train_loss: 0.03705 valid_loss: 0.03811\n",
      "EarlyStopping counter: 2 out of 35\n",
      "[ 82/500] train_loss: 0.03700 valid_loss: 0.03799\n",
      "EarlyStopping counter: 3 out of 35\n",
      "[ 83/500] train_loss: 0.03698 valid_loss: 0.03810\n",
      "EarlyStopping counter: 4 out of 35\n",
      "[ 84/500] train_loss: 0.03690 valid_loss: 0.03799\n",
      "EarlyStopping counter: 5 out of 35\n",
      "[ 85/500] train_loss: 0.03677 valid_loss: 0.03837\n",
      "EarlyStopping counter: 6 out of 35\n",
      "[ 86/500] train_loss: 0.03683 valid_loss: 0.03811\n",
      "EarlyStopping counter: 7 out of 35\n",
      "[ 87/500] train_loss: 0.03711 valid_loss: 0.03796\n",
      "Validation loss decreased (0.037977 --> 0.037958).  Saving model ...\n",
      "[ 88/500] train_loss: 0.03675 valid_loss: 0.03800\n",
      "EarlyStopping counter: 1 out of 35\n",
      "[ 89/500] train_loss: 0.03689 valid_loss: 0.03778\n",
      "Validation loss decreased (0.037958 --> 0.037780).  Saving model ...\n",
      "[ 90/500] train_loss: 0.03695 valid_loss: 0.03795\n",
      "EarlyStopping counter: 1 out of 35\n",
      "[ 91/500] train_loss: 0.03758 valid_loss: 0.03817\n",
      "EarlyStopping counter: 2 out of 35\n",
      "[ 92/500] train_loss: 0.03689 valid_loss: 0.03808\n",
      "EarlyStopping counter: 3 out of 35\n",
      "[ 93/500] train_loss: 0.03716 valid_loss: 0.03845\n",
      "EarlyStopping counter: 4 out of 35\n",
      "[ 94/500] train_loss: 0.03754 valid_loss: 0.03929\n",
      "EarlyStopping counter: 5 out of 35\n",
      "[ 95/500] train_loss: 0.03734 valid_loss: 0.03812\n",
      "EarlyStopping counter: 6 out of 35\n",
      "[ 96/500] train_loss: 0.03687 valid_loss: 0.03770\n",
      "Validation loss decreased (0.037780 --> 0.037699).  Saving model ...\n",
      "[ 97/500] train_loss: 0.03675 valid_loss: 0.03799\n",
      "EarlyStopping counter: 1 out of 35\n",
      "[ 98/500] train_loss: 0.03697 valid_loss: 0.03784\n",
      "EarlyStopping counter: 2 out of 35\n",
      "[ 99/500] train_loss: 0.03674 valid_loss: 0.03777\n",
      "EarlyStopping counter: 3 out of 35\n",
      "[100/500] train_loss: 0.03663 valid_loss: 0.03790\n",
      "EarlyStopping counter: 4 out of 35\n",
      "[101/500] train_loss: 0.03663 valid_loss: 0.03753\n",
      "Validation loss decreased (0.037699 --> 0.037535).  Saving model ...\n",
      "[102/500] train_loss: 0.03675 valid_loss: 0.03760\n",
      "EarlyStopping counter: 1 out of 35\n",
      "[103/500] train_loss: 0.03657 valid_loss: 0.03775\n",
      "EarlyStopping counter: 2 out of 35\n",
      "[104/500] train_loss: 0.03665 valid_loss: 0.03779\n",
      "EarlyStopping counter: 3 out of 35\n",
      "[105/500] train_loss: 0.03664 valid_loss: 0.03773\n",
      "EarlyStopping counter: 4 out of 35\n",
      "[106/500] train_loss: 0.03696 valid_loss: 0.03783\n",
      "EarlyStopping counter: 5 out of 35\n",
      "[107/500] train_loss: 0.03688 valid_loss: 0.03761\n",
      "EarlyStopping counter: 6 out of 35\n",
      "[108/500] train_loss: 0.03660 valid_loss: 0.03768\n",
      "EarlyStopping counter: 7 out of 35\n",
      "[109/500] train_loss: 0.03643 valid_loss: 0.03755\n",
      "EarlyStopping counter: 8 out of 35\n",
      "[110/500] train_loss: 0.03669 valid_loss: 0.03770\n",
      "EarlyStopping counter: 9 out of 35\n",
      "[111/500] train_loss: 0.03659 valid_loss: 0.03750\n",
      "Validation loss decreased (0.037535 --> 0.037496).  Saving model ...\n",
      "[112/500] train_loss: 0.03645 valid_loss: 0.03747\n",
      "Validation loss decreased (0.037496 --> 0.037465).  Saving model ...\n",
      "[113/500] train_loss: 0.03639 valid_loss: 0.03750\n",
      "EarlyStopping counter: 1 out of 35\n",
      "[114/500] train_loss: 0.03677 valid_loss: 0.03795\n",
      "EarlyStopping counter: 2 out of 35\n",
      "[115/500] train_loss: 0.03667 valid_loss: 0.03768\n",
      "EarlyStopping counter: 3 out of 35\n",
      "[116/500] train_loss: 0.03631 valid_loss: 0.03730\n",
      "Validation loss decreased (0.037465 --> 0.037305).  Saving model ...\n",
      "[117/500] train_loss: 0.03636 valid_loss: 0.03756\n",
      "EarlyStopping counter: 1 out of 35\n",
      "[118/500] train_loss: 0.03632 valid_loss: 0.03744\n",
      "EarlyStopping counter: 2 out of 35\n",
      "[119/500] train_loss: 0.03618 valid_loss: 0.03750\n",
      "EarlyStopping counter: 3 out of 35\n",
      "[120/500] train_loss: 0.03612 valid_loss: 0.03711\n",
      "Validation loss decreased (0.037305 --> 0.037112).  Saving model ...\n",
      "[121/500] train_loss: 0.03622 valid_loss: 0.03729\n",
      "EarlyStopping counter: 1 out of 35\n",
      "[122/500] train_loss: 0.03697 valid_loss: 0.03812\n",
      "EarlyStopping counter: 2 out of 35\n",
      "[123/500] train_loss: 0.03671 valid_loss: 0.03774\n",
      "EarlyStopping counter: 3 out of 35\n",
      "[124/500] train_loss: 0.03665 valid_loss: 0.03772\n",
      "EarlyStopping counter: 4 out of 35\n",
      "[125/500] train_loss: 0.03648 valid_loss: 0.03776\n",
      "EarlyStopping counter: 5 out of 35\n",
      "[126/500] train_loss: 0.03679 valid_loss: 0.03797\n",
      "EarlyStopping counter: 6 out of 35\n",
      "[127/500] train_loss: 0.03733 valid_loss: 0.03802\n",
      "EarlyStopping counter: 7 out of 35\n",
      "[128/500] train_loss: 0.03683 valid_loss: 0.03807\n",
      "EarlyStopping counter: 8 out of 35\n",
      "[129/500] train_loss: 0.03673 valid_loss: 0.03743\n",
      "EarlyStopping counter: 9 out of 35\n",
      "[130/500] train_loss: 0.03622 valid_loss: 0.03733\n",
      "EarlyStopping counter: 10 out of 35\n",
      "[131/500] train_loss: 0.03605 valid_loss: 0.03728\n",
      "EarlyStopping counter: 11 out of 35\n",
      "[132/500] train_loss: 0.03608 valid_loss: 0.03734\n",
      "EarlyStopping counter: 12 out of 35\n",
      "[133/500] train_loss: 0.03611 valid_loss: 0.03722\n",
      "EarlyStopping counter: 13 out of 35\n",
      "[134/500] train_loss: 0.03607 valid_loss: 0.03725\n",
      "EarlyStopping counter: 14 out of 35\n",
      "[135/500] train_loss: 0.03616 valid_loss: 0.03729\n",
      "EarlyStopping counter: 15 out of 35\n",
      "[136/500] train_loss: 0.03630 valid_loss: 0.03744\n",
      "EarlyStopping counter: 16 out of 35\n",
      "[137/500] train_loss: 0.03622 valid_loss: 0.03727\n",
      "EarlyStopping counter: 17 out of 35\n",
      "[138/500] train_loss: 0.03626 valid_loss: 0.03749\n",
      "EarlyStopping counter: 18 out of 35\n",
      "[139/500] train_loss: 0.03629 valid_loss: 0.03732\n",
      "EarlyStopping counter: 19 out of 35\n",
      "[140/500] train_loss: 0.03633 valid_loss: 0.03739\n",
      "EarlyStopping counter: 20 out of 35\n",
      "[141/500] train_loss: 0.03624 valid_loss: 0.03726\n",
      "EarlyStopping counter: 21 out of 35\n",
      "[142/500] train_loss: 0.03621 valid_loss: 0.03749\n",
      "EarlyStopping counter: 22 out of 35\n",
      "[143/500] train_loss: 0.03627 valid_loss: 0.03745\n",
      "EarlyStopping counter: 23 out of 35\n",
      "[144/500] train_loss: 0.03624 valid_loss: 0.03696\n",
      "Validation loss decreased (0.037112 --> 0.036956).  Saving model ...\n",
      "[145/500] train_loss: 0.03590 valid_loss: 0.03707\n",
      "EarlyStopping counter: 1 out of 35\n",
      "[146/500] train_loss: 0.03614 valid_loss: 0.03701\n",
      "EarlyStopping counter: 2 out of 35\n",
      "[147/500] train_loss: 0.03587 valid_loss: 0.03685\n",
      "Validation loss decreased (0.036956 --> 0.036854).  Saving model ...\n",
      "[148/500] train_loss: 0.03579 valid_loss: 0.03718\n",
      "EarlyStopping counter: 1 out of 35\n",
      "[149/500] train_loss: 0.03605 valid_loss: 0.03703\n",
      "EarlyStopping counter: 2 out of 35\n",
      "[150/500] train_loss: 0.03589 valid_loss: 0.03719\n",
      "EarlyStopping counter: 3 out of 35\n",
      "[151/500] train_loss: 0.03616 valid_loss: 0.03802\n",
      "EarlyStopping counter: 4 out of 35\n",
      "[152/500] train_loss: 0.03620 valid_loss: 0.03712\n",
      "EarlyStopping counter: 5 out of 35\n",
      "[153/500] train_loss: 0.03585 valid_loss: 0.03717\n",
      "EarlyStopping counter: 6 out of 35\n",
      "[154/500] train_loss: 0.03607 valid_loss: 0.03727\n",
      "EarlyStopping counter: 7 out of 35\n",
      "[155/500] train_loss: 0.03606 valid_loss: 0.03710\n",
      "EarlyStopping counter: 8 out of 35\n",
      "[156/500] train_loss: 0.03601 valid_loss: 0.03735\n",
      "EarlyStopping counter: 9 out of 35\n",
      "[157/500] train_loss: 0.03610 valid_loss: 0.03720\n",
      "EarlyStopping counter: 10 out of 35\n",
      "[158/500] train_loss: 0.03598 valid_loss: 0.03739\n",
      "EarlyStopping counter: 11 out of 35\n",
      "[159/500] train_loss: 0.03616 valid_loss: 0.03717\n",
      "EarlyStopping counter: 12 out of 35\n",
      "[160/500] train_loss: 0.03682 valid_loss: 0.03858\n",
      "EarlyStopping counter: 13 out of 35\n",
      "[161/500] train_loss: 0.03713 valid_loss: 0.03757\n",
      "EarlyStopping counter: 14 out of 35\n",
      "[162/500] train_loss: 0.03618 valid_loss: 0.03735\n",
      "EarlyStopping counter: 15 out of 35\n",
      "[163/500] train_loss: 0.03625 valid_loss: 0.03736\n",
      "EarlyStopping counter: 16 out of 35\n",
      "[164/500] train_loss: 0.03621 valid_loss: 0.03731\n",
      "EarlyStopping counter: 17 out of 35\n",
      "[165/500] train_loss: 0.03626 valid_loss: 0.03746\n",
      "EarlyStopping counter: 18 out of 35\n",
      "[166/500] train_loss: 0.03639 valid_loss: 0.03734\n",
      "EarlyStopping counter: 19 out of 35\n",
      "[167/500] train_loss: 0.03621 valid_loss: 0.03765\n",
      "EarlyStopping counter: 20 out of 35\n",
      "[168/500] train_loss: 0.03674 valid_loss: 0.03809\n",
      "EarlyStopping counter: 21 out of 35\n",
      "[169/500] train_loss: 0.03716 valid_loss: 0.03812\n",
      "EarlyStopping counter: 22 out of 35\n",
      "[170/500] train_loss: 0.03698 valid_loss: 0.03789\n",
      "EarlyStopping counter: 23 out of 35\n",
      "[171/500] train_loss: 0.03665 valid_loss: 0.03771\n",
      "EarlyStopping counter: 24 out of 35\n",
      "[172/500] train_loss: 0.03646 valid_loss: 0.03744\n",
      "EarlyStopping counter: 25 out of 35\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[173/500] train_loss: 0.03632 valid_loss: 0.03736\n",
      "EarlyStopping counter: 26 out of 35\n",
      "[174/500] train_loss: 0.03628 valid_loss: 0.03742\n",
      "EarlyStopping counter: 27 out of 35\n",
      "[175/500] train_loss: 0.03622 valid_loss: 0.03752\n",
      "EarlyStopping counter: 28 out of 35\n",
      "[176/500] train_loss: 0.03624 valid_loss: 0.03756\n",
      "EarlyStopping counter: 29 out of 35\n",
      "[177/500] train_loss: 0.03606 valid_loss: 0.03728\n",
      "EarlyStopping counter: 30 out of 35\n",
      "[178/500] train_loss: 0.03610 valid_loss: 0.03730\n",
      "EarlyStopping counter: 31 out of 35\n",
      "[179/500] train_loss: 0.03619 valid_loss: 0.03730\n",
      "EarlyStopping counter: 32 out of 35\n",
      "[180/500] train_loss: 0.03605 valid_loss: 0.03723\n",
      "EarlyStopping counter: 33 out of 35\n",
      "[181/500] train_loss: 0.03623 valid_loss: 0.03753\n",
      "EarlyStopping counter: 34 out of 35\n",
      "[182/500] train_loss: 0.03597 valid_loss: 0.03702\n",
      "EarlyStopping counter: 35 out of 35\n",
      "Early stopping\n"
     ]
    }
   ],
   "source": [
    "# batch_size = 64\n",
    "patience = 35\n",
    "max_epochs = 500\n",
    "\n",
    "# model_, train_loss, val_loss = model_train(model, batch_size, patience, max_epochs)\n",
    "model_, train_loss, val_loss = model_train(model, patience, max_epochs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
